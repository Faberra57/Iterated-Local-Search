{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQvRgd4IJtTa"
   },
   "source": [
    "# Imports of modules\n",
    "\n",
    "Below we import some modules necessary to make this code work properly.\n",
    "\n",
    "You can add other modules here which you might need for your algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9M3AxrugJOqT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a utilisé le module time pour mesurer les temps d'exécution des différentes parties du code pour comprendre l'influence des paramètres sur les temps d'exécution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlhgCEc8J9-g"
   },
   "source": [
    "# Definitions of constants\n",
    "\n",
    "In the cell below we define some constants that we need in the meta-heuristic.\n",
    "\n",
    "The paths to the data files are also specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pUZEK9kzKJv3"
   },
   "outputs": [],
   "source": [
    "# ILS parameters\n",
    "\n",
    "#MAX_ITER = 10     # maximum number of iterations (Stopping criterion of ILS)\n",
    "#MAX_ITER_NI = 20   # number of iterations without improvement of the objective function (Stopping criterion of ILS)\n",
    "#MAX_ITER_LS = 30  # maximum number of iterations of the local search operator (Outer loop)\n",
    "#MAX_SWAPS = 1      # maximum number of swaps of the local search operator (Inner loop)\n",
    "#NB_SWAPS = 5       # number of swaps in the perturbation operator\n",
    "#ALPHA = 0.05\n",
    "optimal_sol = 2.484863919811e+07\n",
    "# Path to data file\n",
    "\n",
    "SINPUT_DATA = \"InputDataEnergySmallInstance.xlsx\"  # Small instance\n",
    "INPUT_DATA = \"InputDataEnergyLargeInstance.xlsx\"  # Large instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres de ILS ne sont plus **définis de manière globale** mais de **manière locale** pour pouvoir les faire varier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pQBRZywKzBE"
   },
   "source": [
    "# Functions to load and prepare the data\n",
    "\n",
    "In the cell below, you find three functions:\n",
    "- first, read_excel_data, which returns the values of a specific sheet in an Excel file,\n",
    "- then, a function to calculate the length of an eadge A--B in the network based on the coordinates of nodes A and B,\n",
    "- and finally, create_data_model which fills the data dictionary with the data from the various sheets of the Excel file, as well as some dependent data, which is calculated from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IDT2OUseKOhz"
   },
   "outputs": [],
   "source": [
    "def read_excel_data(filename: str, sheet_name: str) -> np.ndarray:\n",
    "    \"\"\"Read data from an excel spreadsheet.\n",
    "\n",
    "    :param filename:\n",
    "    :param sheet_name:\n",
    "    :return: sheet data\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(filename, sheet_name=sheet_name, header=None)\n",
    "    values = data.values\n",
    "    return values\n",
    "\n",
    "\n",
    "def compute_edge_lengths(nodes_coord: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute distance matrix between each pair of nodes.\n",
    "\n",
    "    :param nodes_coord: coordinates of each node as a N*2 array\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    edges_length = np.zeros((len(nodes_coord), len(nodes_coord)))\n",
    "    for i in range(0, len(nodes_coord)):\n",
    "        for j in range(0, len(nodes_coord)):\n",
    "            edges_length[i, j] = distance.euclidean((nodes_coord[i]), (nodes_coord[j]))\n",
    "    return edges_length\n",
    "\n",
    "\n",
    "def create_data_model() -> dict:\n",
    "    \"\"\"Create the data model which gathers all problem parameters.\n",
    "\n",
    "    :return: data model structure\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # This section contains all required data #\n",
    "    data['SourceNum'] = read_excel_data(INPUT_DATA, \"SourceNum\")[0][0]\n",
    "\n",
    "    # Nodes Cordinate Read From Excel#\n",
    "    data['NodesCord'] = read_excel_data(INPUT_DATA, \"NodesCord\")\n",
    "\n",
    "    # Building Cordinate Read From Excel#\n",
    "    #EdgesDemand = read_excel_data(INPUT_DATA, \"EdgesDemand\")\n",
    "\n",
    "    # Fixed Unit Cost\n",
    "    data['FixedUnitCost'] = read_excel_data(INPUT_DATA, \"FixedUnitCost\")\n",
    "\n",
    "    # Edges Length Calculation based the Nodes Cordinate\n",
    "    data['EdgesLength'] = np.matrix.round(compute_edge_lengths(data['NodesCord']))\n",
    "\n",
    "    # Fixed Instalation cost\n",
    "    data['cfix'] = data['EdgesLength'] * data['FixedUnitCost']\n",
    "\n",
    "    # Number of Nodes\n",
    "    data['node_num'] = len(data['NodesCord'])\n",
    "\n",
    "    # Revenue of Fulfiling the Edges Demand\n",
    "    data['crev'] = read_excel_data(INPUT_DATA, \"crev(cijrev)\")\n",
    "\n",
    "    # Penalty of Unmet Demand\n",
    "    data['pumd'] = read_excel_data(INPUT_DATA, \"pumd(pijumd)\")\n",
    "\n",
    "    # Cost of Heat Production in the Sources\n",
    "    data['cheat'] = read_excel_data(INPUT_DATA, \"cheat(ciheat)\")\n",
    "\n",
    "    # Variable Cost of Heat Transferring through the Edges\n",
    "    data['cvar'] = read_excel_data(INPUT_DATA, \"cvar(cijvar)\")\n",
    "\n",
    "    # Variable Thermal Losses\n",
    "    data['vvar'] = read_excel_data(INPUT_DATA, \"vvar(thetaijvar)\")\n",
    "\n",
    "    # Fixed Thermal Losses\n",
    "    data['vfix'] = read_excel_data(INPUT_DATA, \"vfix(thetaijfix)\")\n",
    "\n",
    "    # Full Load Hours for the Sources\n",
    "    data['Tflh'] = read_excel_data(INPUT_DATA, \"Tflh(Tiflh)\")\n",
    "\n",
    "    # Concurrence Effect\n",
    "    data['Betta'] = read_excel_data(INPUT_DATA, \"Betta\")\n",
    "\n",
    "    # Connect Quota\n",
    "    data['Lambda'] = read_excel_data(INPUT_DATA, \"Lambda\")\n",
    "\n",
    "    # Annuity Factor for Investment Cost\n",
    "    data['Alpha'] = read_excel_data(INPUT_DATA, \"Alpha\")\n",
    "\n",
    "    # Edges Peak Demand\n",
    "    data['EdgesDemandPeak'] = read_excel_data(INPUT_DATA, \"EdgesDemandPeak(dij)\")\n",
    "\n",
    "    # Edges Annual Demand\n",
    "    data['EdgesDemandAnnual'] = read_excel_data(INPUT_DATA, \"EdgesDemandAnnual(Dij)\")\n",
    "\n",
    "    # Edges Maximum Capacity\n",
    "    data['Cmax'] = read_excel_data(INPUT_DATA, \"Cmax(cijmax)\")\n",
    "\n",
    "    # Cost of Maintenance\n",
    "    data['com'] = read_excel_data(INPUT_DATA, \"com(cijom)\")\n",
    "\n",
    "    # Source Maximum Capacity\n",
    "    data['SourceMaxCap'] = read_excel_data(INPUT_DATA, \"SourceMaxCap(Qimax)\")\n",
    "\n",
    "    # Dependent Parameters\n",
    "    data['kfix'] = data['cfix'] * data['Alpha'] * data['EdgesLength'] + data['com'] * data['EdgesLength']\n",
    "    data['kvar'] = data['cvar'] * data['EdgesLength'] * data['Alpha']\n",
    "    data['rheat'] = data['crev'] * data['EdgesDemandAnnual'] * data['Lambda']\n",
    "    data['kheat'] = (data['Tflh'] * data['cheat']) / data['Betta']\n",
    "    data['Etta'] = 1 - data['EdgesLength'] * data['vvar']\n",
    "    data['Delta'] = data['EdgesDemandPeak'] * data['Betta'] * data['Lambda'] + data['EdgesLength'] * data['vfix']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMNwG52HLi8V"
   },
   "source": [
    "# Functions to calculate the objective function from the solution representation\n",
    "\n",
    "The cell below contains 2 functions to calculate the objective function of an individual:\n",
    "- first `prufer_to_tree` which transforms the Prüfer representation of a solution into a tree,\n",
    "- second, `tree_to_prufer` which transforms a tree into a Prüfer representation,\n",
    "- third, `compute_of` which calculates the fitness (or objective function) of an individual (or a solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h10apbZsLHST"
   },
   "outputs": [],
   "source": [
    "def prufer_to_tree(prufer_sequence: list) -> nx.Graph:\n",
    "    \"\"\"Transform the Prüfer representation into a tree.\n",
    "\n",
    "    :param a: Prüfer sequence representing a tree\n",
    "    :return: tree as a graph structure\n",
    "    \"\"\"\n",
    "    return nx.from_prufer_sequence(prufer_sequence)\n",
    "\n",
    "\n",
    "def tree_to_prufer(tree: nx.Graph) -> list:\n",
    "    \"\"\"Transform a tree into a Prüfer sequence.\n",
    "\n",
    "    :param tree:\n",
    "    :return: Prüfer sequence representing the tree\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return nx.to_prufer_sequence(tree)\n",
    "\n",
    "\n",
    "def compute_of(individual: list, data: dict) -> float:\n",
    "    \"\"\"Calculate the objective function of the individual.\n",
    "\n",
    "    :param individual: solution as a tree in Prüfer representation\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: value of the objective function for given individual\n",
    "    \"\"\"\n",
    "    graph = prufer_to_tree(individual)\n",
    "    tree_edges = list(graph.edges)\n",
    "    all_pairs_path = dict(nx.all_pairs_shortest_path(graph))\n",
    "    path_from_source = all_pairs_path[data['SourceNum']]\n",
    "\n",
    "    P_in = np.zeros((len(graph.edges)+1, len(graph.edges)+1))\n",
    "    P_out = np.zeros((len(graph.edges)+1, len(graph.edges)+1))\n",
    "\n",
    "    hubs = np.unique(individual)\n",
    "    spokes = list(set([i for i in range(len(individual)+2)]) - set(hubs))\n",
    "\n",
    "    for i in spokes:\n",
    "        A = path_from_source[i]\n",
    "        e = 0\n",
    "        for k in range(0, len(A)-1):\n",
    "            if e == 0:\n",
    "                P_out[A[len(A)-k-2], A[len(A)-k-1]] = 0\n",
    "                e = e + 1\n",
    "            else:\n",
    "                P_out[A[len(A)-k-2], A[len(A)-k-1]] = sum(P_in[A[len(A)-k-1]])\n",
    "\n",
    "            P_in[A[len(A)-k-2], A[len(A)-k-1]] = (P_out[A[len(A)-k-2], A[len(A)-k-1]] + data['Delta'][A[len(A)-k-2], A[len(A)-k-1]])/data['Etta'][A[len(A)-k-2], A[len(A)-k-1]]\n",
    "\n",
    "    fitness = 0\n",
    "    metDemand = 0\n",
    "    for i in range(len(tree_edges)):\n",
    "        fitness = fitness + data['kfix'][tree_edges[i]] - data['rheat'][tree_edges[i]] + data['kvar'][tree_edges[i]] * (P_in[tree_edges[i][0], tree_edges[i][1]])\n",
    "        metDemand = metDemand + 2 * data['EdgesDemandAnnual'][tree_edges[i]] * data['pumd'][tree_edges[i]]\n",
    "    fitness = fitness + data['kheat'][data['SourceNum']] * sum(P_in[data['SourceNum']])\n",
    "    fitness = fitness + 0.5*((data['EdgesDemandAnnual'] * data['pumd']).sum() - metDemand)\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons la représentation de **Prüfer des arbres**. La représentation de Prüfer permet de créer une **bijection entre un arbre et une liste.** Cela signifie qu'au lieu de modifier directement l'arbre, on peut modifier la liste de Prüfer, puis inverser la bijection pour retrouver l'arbre avec les modifications appliquées.\n",
    "\n",
    "L'avantage de cette représentation réside dans la **rapidité d'exécution des modifications d'un arbre**. Elle simplifie également le code, car un arbre est une **structure naturellement récursive**, ce qui aurait nécessité que toutes nos **fonctions soient récursives pour interagir avec l'arbre**. En revanche, la liste de Prüfer est une **structure linéaire**, ce qui permet une interaction plus facile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ozSvLncMWrt"
   },
   "source": [
    "# Functions to create solutions or individuals\n",
    "\n",
    "The cell below contains two functions regarding individuals:\n",
    "\n",
    "- first, `generate_individual` to create a random individual,\n",
    "- second, `initial_solution` which returns this single randomly generated individual and its fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XotlcDdbLAKn"
   },
   "outputs": [],
   "source": [
    "def generate_individual(nb_nodes: int) -> list:\n",
    "    \"\"\"Generate a random individual.\n",
    "\n",
    "    The created nodes will be labelled as integer from 0 to `nb_nodes`-1\n",
    "\n",
    "    :param nb_nodes: total number of nodes in an individual tree\n",
    "    :return: Prüfer representation of a random tree with given number of nodes\n",
    "    \"\"\"\n",
    "    individual = np.ndarray.tolist(np.random.randint(0, high=nb_nodes-1, size=nb_nodes-2, dtype='int'))\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def initial_solution(data: dict) -> tuple:\n",
    "    \"\"\"Generate a random solution and calculate its fitness.\n",
    "\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: random solution in Prüfer representation, and its objective function value\n",
    "    \"\"\"\n",
    "    # here we are generating only one initial solution\n",
    "    solution = generate_individual(data['node_num'])\n",
    "    return solution, compute_of(solution, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhReYN5zMoFR"
   },
   "source": [
    "# Functions for the local search\n",
    "\n",
    "Below you can find functions to perform a local search:\n",
    "- first the general high-level `local_search` function,\n",
    "- second the `swap` function, which implements a swap operator,\n",
    "- third the `swap_neighborhood` function which generates the neighborhood based on the swap operator,\n",
    "- and finally the `unique_pairs` function, used by `swap_neighborhood`, wich generates unique pairs indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7qPzoSOiNiFL"
   },
   "outputs": [],
   "source": [
    "def local_search(sol: list, of: float, data: dict , MAX_ITER_LS : int) -> tuple:\n",
    "    \"\"\"Perform a local search.\n",
    "\n",
    "    :param sol: input solution\n",
    "    :param of: objective function value of input solution\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: best neighbouring solution, and its objective function value\n",
    "    \"\"\"\n",
    "    \n",
    "    best_of = of\n",
    "    best_sol = sol\n",
    "\n",
    "    # Main loop local search\n",
    "    # Local search operators is repeated MAX_ITER_LS times\n",
    "    for _ in range(MAX_ITER_LS):\n",
    "\n",
    "        #print('MAX_ITER_LS',nb_iterations)\n",
    "        # use an operator to perform local search\n",
    "        best_of , best_sol = swap_neighborhood(best_sol, best_of, data)\n",
    "    return best_sol, best_of \n",
    "\n",
    "\n",
    "def swap(i: int, j: int, sol: list) -> list:\n",
    "    \"\"\"Swap operator.\n",
    "\n",
    "    This function simply swaps the nodes at position `i` and `j` in the Prüfer sequence.\n",
    "\n",
    "    :param i: first position in `sol` sequence\n",
    "    :param j: second position in `sol` sequence\n",
    "    :param sol: parent solution to modify\n",
    "    :return: new solution\n",
    "    \"\"\"\n",
    "    \n",
    "    sol[i], sol[j] = sol[j], sol[i]\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "# The following function is a function to generate the neighbours of the given solution \"sol\"\n",
    "def swap_neighborhood(sol: list, best_of: float, data: dict) -> tuple:\n",
    "    \"\"\"Neighborhood generation with a swap operator.\n",
    "\n",
    "    All pairs of possible neighbours are investigated and create a solution and its objective function value each.\n",
    "\n",
    "    :param sol: parent solution which neighbourhood to search\n",
    "    :param best_of: parent solution objective function value\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: list of neighbouring solutions, and corresponding list of neighbours objective function values\n",
    "    \"\"\"\n",
    "    n = data['node_num']-2\n",
    "    best_sol= sol\n",
    "    computed = 0\n",
    "    for i, j in unique_pairs(n):\n",
    "        sol = swap(i,j,sol)\n",
    "        computed = compute_of(sol,data)\n",
    "        if computed< best_of:\n",
    "            best_sol = sol\n",
    "            best_of = computed\n",
    "    return best_of , best_sol\n",
    "    \n",
    "\n",
    "def unique_pairs(n: int):\n",
    "    \"\"\"Generator producing pairs of indexes in range(n).\n",
    "\n",
    "    :param n:\n",
    "    :return: pair of indexes (generator)\n",
    "    \"\"\"\n",
    "    for i in range(n-1):\n",
    "        for j in range(i + 1, n-1):\n",
    "            yield i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai changé la logique du code pour l'optimiser, en effet je cherche le minimum des voisins directement dans la fonction swap_neighborhood pour éviter de devoir trouver le minimum d'un liste dans local_search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gDKv178N0NO"
   },
   "source": [
    "# Functions for the perturbation of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6SxjOl1cNjR_"
   },
   "outputs": [],
   "source": [
    "def random_swap(sol: list, data : dict) -> list:\n",
    "    \"\"\"Random perturation.\n",
    "\n",
    "    Applies `NB_SWAPS` random swap operations on the solution.\n",
    "\n",
    "    :param sol: parent solution\n",
    "    :return: modified solution\n",
    "    \"\"\"\n",
    "    n = data['node_num']-2\n",
    "    i = random.randint(0, n - 1)\n",
    "    j = random.randint(0, n - 1)\n",
    "    while (i==j):\n",
    "        j = random.randint(0, n - 1)\n",
    "    sol = swap(i, j, sol)\n",
    "\n",
    "    return sol\n",
    "\n",
    "# This function is the main body of the perturbation operator, wherein the random_swap function is called\n",
    "def perturb(sol: list, data: dict, NB_SWAPS : int) -> tuple:\n",
    "    \"\"\"Add random perturbations on the solution.\n",
    "\n",
    "    :param sol: current solution to modify\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: new solution, and its objective function value\n",
    "    \"\"\"\n",
    "    pert_sol=sol\n",
    "    for i in range(NB_SWAPS):\n",
    "        pert_sol=random_swap(pert_sol, data)\n",
    "    pert_of = compute_of(sol,data)\n",
    "    \n",
    "    return pert_sol, pert_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du temps d'exécution des différentes parties #\n",
    "\n",
    "Un tour de boucle du local search ~ 0.7 s. \n",
    "\n",
    "un tour de boucle de perturb peut être considéré en temps constant.\n",
    "\n",
    "Dans notre fonction main, on fait max(MAX_ITER_NI , MAX_ITER) * MAX_ITER_LS la boucle du local search \n",
    "\n",
    "Avec les paramètres proposés MAX_ITER = 100, MAX_ITER_NI = 50 et MAX_ITER_LS = 100 cela prendrait 116 minutes ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvKfEcCyN9V1"
   },
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "id": "0kCpz-PhObA_",
    "outputId": "350ab115-1172-48d5-8466-badb47b67fd7"
   },
   "outputs": [],
   "source": [
    "def main(MAX_ITER : int, MAX_ITER_NI : int , MAX_ITER_LS : int , MAX_SWAPS : int , NB_SWAPS: int , ALPHA : float) -> float:\n",
    "    \n",
    "    #start=time.time()\n",
    "    \n",
    "    \n",
    "    #Parameter\n",
    "    #MAX_ITER      # maximum number of iterations (Stopping criterion of ILS)\n",
    "    #MAX_ITER_NI    # number of iterations without improvement of the objective function (Stopping criterion of ILS)\n",
    "    #MAX_ITER_LS   # maximum number of iterations of the local search operator (Outer loop)\n",
    "    #MAX_SWAPS       # maximum number of swaps of the local search operator (Inner loop)\n",
    "    #NB_SWAPS        # number of swaps in the perturbation operator\n",
    "    #ALPHA          # critère d'acceptation sur la pertubation\n",
    "\n",
    "    # *************************Initialisation***************************\n",
    "    # initialise the data\n",
    "    \n",
    "    data = create_data_model()\n",
    "\n",
    "    # init number of iterations\n",
    "    nb_iterations = 0\n",
    "\n",
    "    # find initial solution (just one) with a constructive heuristic\n",
    "    best_sol, best_of = initial_solution(data)\n",
    "\n",
    "    # **************************Local Search******************************\n",
    "\n",
    "    best_sol, best_of = local_search(best_sol, best_of, data, MAX_ITER_LS)\n",
    "    best_known = best_sol\n",
    "    best_of_known = best_of\n",
    "\n",
    "    # ********************************************************************\n",
    "\n",
    "    # ******************************ILS***********************************\n",
    "    flag_continue = True\n",
    "    improve = 0\n",
    "\n",
    "    while flag_continue and nb_iterations <= MAX_ITER and improve <= MAX_ITER_NI:\n",
    "\n",
    "        nb_iterations += 1\n",
    "        \n",
    "        \n",
    "        # ******************Perturbation**********************************\n",
    "        pert_sol, pert_of = perturb(best_sol, data, NB_SWAPS)\n",
    "        # print(pert_of)\n",
    "        #print('\\nPertubation DONE')\n",
    "        # ******************Local Search***********************************\n",
    "        best_sol_pert, best_of_pert = local_search(pert_sol, pert_of, data, MAX_ITER_LS)\n",
    "        # print(best_of_pert)\n",
    "        #print('\\nLocal Search DONE')\n",
    "        # ******************Aceptance criterion***************************\n",
    "        if(best_of_pert < best_of_known):\n",
    "            best_known = best_sol_pert\n",
    "            best_of_known = best_of_pert\n",
    "            improve = 0\n",
    "        else:\n",
    "            improve += 1\n",
    "\n",
    "        if (best_of_pert < best_of * (1 + ALPHA)):\n",
    "            best_of = best_of_pert\n",
    "            best_sol = best_sol_pert\n",
    "        #else:\n",
    "            #flag_continue = False\n",
    "            #print('Stop à cause du flag')\n",
    "        print('Nombre d\\'itération :',nb_iterations, end='\\r')\n",
    "    return float(best_of_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a une fonciton obejctive 7.695123e+08 avec un écart de la valeur optimal de 7.446637e+08\n"
     ]
    }
   ],
   "source": [
    "resultat = main(2,1,10,1,1,0.05)\n",
    "print(f'On a une fonciton obejctive {round(resultat):e} avec un écart de la valeur optimal de {round(abs(resultat- optimal_sol)):e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après 40 minutes d'exécution, on obtient un résultat vraiment **peu satisfaisant**. Cela peut être dû à un mauvais choix des paramètres. En effet, soit notre algorithme de recherche locale (ILS) ne cherche pas assez en profondeur les minima locaux (**paramètre MAX_ITER_LS trop faible**), soit il n'explore pas assez l'espace de recherche pour découvrir de nouvelles zones avec des minima locaux beaucoup plus faibles (**paramètres ALPHA et NB_SWAPS trop faibles**). On peut également remettre en question le choix des opérateurs de perturbation utilisés dans la recherche locale et dans la perturbation de la solution, qui pourraient ne pas être assez performants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation naïf des metaparamètres #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a vu que notre fonction main dépendait des **metaparamètres** suivants :<br>\n",
    "\n",
    "    MAX_ITER    # maximum number of iterations (Stopping criterion of ILS)\n",
    "    MAX_ITER_NI    # number of iterations without improvement of the objective function (Stopping criterion of ILS)\n",
    "    MAX_ITER_LS   # maximum number of iterations of the local search operator (Outer loop)\n",
    "    MAX_SWAPS       # maximum number of swaps of the local search operator (Inner loop)\n",
    "    NB_SWAPS        # number of swaps in the perturbation operator\n",
    "    ALPHA          # critère d'acceptation sur la pertubation\n",
    "\n",
    "La solution retournée par notre fonction principale dépend directement de ses paramètres. Nous allons utiliser différents algorithmes pour essayer de trouver un jeu de paramètres optimaux permettant d'obtenir la meilleure solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithme  grid search ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624c1a5dac2d4eca8ef5830e8f99472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search Progress:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'MAX_ITER': 5, 'MAX_ITER_NI': 1, 'MAX_ITER_LS': 20, 'MAX_SWAPS': 5, 'NB_SWAPS': 10, 'ALPHA': 0.1}\n",
      "Best score: 894289613\n"
     ]
    }
   ],
   "source": [
    "# Définir les valeurs des hyperparamètres\n",
    "param_grid = {\n",
    "    'MAX_ITER': [5],\n",
    "    'MAX_ITER_NI': [1, 10, 20],\n",
    "    'MAX_ITER_LS': [1, 10, 20],\n",
    "    'MAX_SWAPS': [5],\n",
    "    'NB_SWAPS': [1, 5, 10],\n",
    "    'ALPHA': [0.1]\n",
    "}\n",
    "\n",
    "# Créer toutes les combinaisons possibles\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "def evaluate_algorithm(params):\n",
    "    return main(**params)\n",
    "\n",
    "best_score = float('+inf')\n",
    "best_params = None\n",
    "\n",
    "# Utiliser tqdm pour suivre la progression\n",
    "for combination in tqdm(combinations, desc=\"Grid Search Progress\"):\n",
    "    score = evaluate_algorithm(combination)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = combination\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, l'algorithme grid search n'est pas adapté ici, car chaque itération prend environ 30 secondes avec de petits paramètres et jusqu'à plusieurs minutes avec de gros paramètres. Avec une grille de seulement **3 niveaux** et de 6 dimensions, nous aurions **729 itérations** de notre fonction principale.\n",
    "\n",
    "En utilisant la bibliothèque Tqdm, nous pouvons suivre la progression de l'algorithme. Il est estimé que l'algorithme prendrait **5 heures** pour se terminer, ce qui n'est pas envisageable.\n",
    "\n",
    "Il faut trouver une méthode d'optimisation **qui limite le nombre d'appels de notre fonction main**.\n",
    "\n",
    "Une première solution consiste à effectuer une recherche en grille sur **un nombre restreint de paramètres**, ce qui réduirait la dimension de notre grille et, par conséquent, le nombre total d'appels. Cependant, cette approche pourrait nous faire manquer certaines **synergies entre les paramètres testés et non testés**.\n",
    "\n",
    "Une solution autre pour contourner ce problème est d'utiliser une méthode d'optimisation probabiliste, telle que **l'optimisation bayésienne**, pour limiter le nombre d'appels à la fonction main.\n",
    "\n",
    "Nous allons maintenant observer l'impact des metaparamètres sur la solution trouvée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact des metaparamètres sur la solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons essayer de comprendre l'impact des différents métaparamètres sur la fonction objectif.\n",
    "\n",
    "En réalité, nous avons deux paramètres à optimiser pour notre fonction : la fonction objectif, qui nous renseigne sur la qualité de la solution trouvée, mais également le temps d'exécution. En effet, si le temps d'exécution n'était pas à prendre en compte, on pourrait se contenter de faire une recherche du maximum global grâce à des méthodes exactes. Ici, on prend en compte le temps et donc il faut essayer de trouver une combinaison de paramètres qui donne une bonne solution en un temps raisonnable.\n",
    "\n",
    "Une première observation est que les paramètres MAX_ITER, MAX_ITER_NI et MAX_ITER_LS sont proportionnels au temps d'exécution ainsi qu'à la qualité de la solution.\n",
    "\n",
    "En effet, plus on augmente ces paramètres, plus la solution s'améliore, mais plus l'exécution prend du temps. On en conclut qu'il n'est donc pas nécessaire de trouver une valeur optimale pour ces paramètres. Le choix de ces paramètres se résume au temps d'exécution que l'on veut bien allouer à notre projet.\n",
    "\n",
    "Le lien entre les paramètres ALPHA, MAX_SWAPS, NB_SWAPS et la fonction objectif n'est pas clair et dépend de la solution initiale. En effet, si notre solution initiale est loin du minimum global, il faudra beaucoup explorer et donc avoir les paramètres d'exploration ALPHA, MAX_SWAPS, NB_SWAPS élevés. À l'inverse, si notre solution initiale est proche du minimum global, des paramètres d'exploration trop élevés pourraient nous faire rater ce minimum.\n",
    "\n",
    "De plus, sauf erreur de notre part, le paramètre MAX_SWAPS ne sert à rien dans notre implémentation.\n",
    "\n",
    "Nous nous retrouvons donc avec deux paramètres à tester via l'algorithme de grid search.\n",
    "\n",
    "De plus on stocke les valeurs de la fonction objectif pour les analyser par la suite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les valeurs de la fonction objectif\n",
    "objective_values = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithme Grid Search ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c9af02fa074263bc7171730c701e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search Progress:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'MAX_ITER': 13, 'MAX_ITER_NI': 9, 'MAX_ITER_LS': 10, 'MAX_SWAPS': 1, 'NB_SWAPS': 50, 'ALPHA': 0.3}\n",
      "Best score: 714886304.8297217\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'MAX_ITER': [13],\n",
    "    'MAX_ITER_NI': [9],\n",
    "    'MAX_ITER_LS': [10],\n",
    "    'MAX_SWAPS': [1],\n",
    "    'NB_SWAPS': [1,10,50],\n",
    "    'ALPHA': [0.01,0.1,0.2,0.3]\n",
    "}\n",
    "\n",
    "# Créer toutes les combinaisons possibles\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Fonction pour évaluer l'algorithme\n",
    "def evaluate_algorithm(params):\n",
    "    return main(**params)\n",
    "\n",
    "# Initialiser les meilleures scores et paramètres\n",
    "best_score = float('+inf')\n",
    "best_params = None\n",
    "\n",
    "\n",
    "# Utiliser tqdm pour suivre la progression\n",
    "for combination in tqdm(combinations, desc=\"Grid Search Progress\"):\n",
    "    score = evaluate_algorithm(combination)\n",
    "    \n",
    "    # Extraire les valeurs de MAX_SWAPS et ALPHA\n",
    "    nb_swaps = combination['NB_SWAPS']\n",
    "    alpha = combination['ALPHA']\n",
    "    # Stocker les valeurs dans le dictionnaire\n",
    "    if (nb_swaps, alpha) not in objective_values:\n",
    "        objective_values[(nb_swaps, alpha)] = []\n",
    "        objective_values[(nb_swaps, alpha)].append(score)\n",
    "    else : \n",
    "        objective_values[(nb_swaps, alpha)].append(score)\n",
    "    # Mettre à jour le meilleur score et les meilleurs paramètres\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = combination\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SWAPS: 1, ALPHA: 0.01, Objective Values: 8.470660e+08\n",
      "MAX_SWAPS: 1, ALPHA: 0.1, Objective Values: 8.552498e+08\n",
      "MAX_SWAPS: 1, ALPHA: 0.2, Objective Values: 8.957163e+08\n",
      "MAX_SWAPS: 1, ALPHA: 0.3, Objective Values: 8.174403e+08\n",
      "MAX_SWAPS: 10, ALPHA: 0.01, Objective Values: 7.781913e+08\n",
      "MAX_SWAPS: 10, ALPHA: 0.1, Objective Values: 8.239375e+08\n",
      "MAX_SWAPS: 10, ALPHA: 0.2, Objective Values: 7.873321e+08\n",
      "MAX_SWAPS: 10, ALPHA: 0.3, Objective Values: 8.019411e+08\n",
      "MAX_SWAPS: 50, ALPHA: 0.01, Objective Values: 7.426026e+08\n",
      "MAX_SWAPS: 50, ALPHA: 0.1, Objective Values: 7.779779e+08\n",
      "MAX_SWAPS: 50, ALPHA: 0.2, Objective Values: 8.044435e+08\n",
      "MAX_SWAPS: 50, ALPHA: 0.3, Objective Values: 7.148863e+08\n"
     ]
    }
   ],
   "source": [
    "# Afficher les valeurs de la fonction objectif\n",
    "for key, values in objective_values.items():\n",
    "    print(f\"MAX_SWAPS: {key[0]}, ALPHA: {key[1]}, Objective Values: {values[0]:e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement on n'arrive pas à trouver de tendance claire et on a plus l'impression que la fonction objectif dépend beaucoup de la solution initiale générée aléatoirement. Cela peut être du au fait qu'on a choisi un nombre relativement faible pour MAX_ITER et pour MAX_ITER_LS afin de limiter le temps d'éxecution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conclure, notre algorithme ILS est plûtot décevant en l'état actuel car il se trompe d'une puissance de 10 par rapport à la solution optimale. Cela peut être dû à divers facteurs comme le mauvais choix des opérateurs de pertubation utilisés dans la fonction local search ou dans la fonction de pertubation de la solution.\n",
    "\n",
    "Les perspectives d'amélioration sont les suivantes:\n",
    "\n",
    "- Essayer d'autres opérateurs de pertubation et les comparer entre eux\n",
    "- Essayer d'implémenter une optimisation bayésienne afin d'optimiser les paramètres ALPHA et NB_SWAPS\n",
    "- Disposer de serveurs pouvant faire tourner la fonction main pendant plusieurs heures avec les paramètres et les opérateurs optimaux afin d'arriver à une solution concluante\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
